{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5ef49c",
   "metadata": {},
   "source": [
    "# Sets things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Define empty dictionary for later\n",
    "dict = {}\n",
    "dict['title'] = []\n",
    "dict['author'] = []\n",
    "dict['price'] = []\n",
    "dict['publication'] = []\n",
    "dict['isbn'] = []\n",
    "dict['year'] = []\n",
    "dict['pubname'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed09b8",
   "metadata": {},
   "source": [
    "# User Agent Randomizer (To avoid bot banning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A bunch of user agent data to rotate between to hopefully evade bot detection\n",
    "headers_list = [\n",
    "# Firefox 77 Mac\n",
    "{\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"DNT\": \"1\",\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\"\n",
    "},\n",
    "# Firefox 77 Windows\n",
    "{\n",
    "\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"DNT\": \"1\",\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\"\n",
    "},\n",
    "# Chrome 83 Mac\n",
    "{\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"DNT\": \"1\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\",\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "\"Sec-Fetch-Site\": \"none\",\n",
    "\"Sec-Fetch-Mode\": \"navigate\",\n",
    "\"Sec-Fetch-Dest\": \"document\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\"\n",
    "},\n",
    "# Chrome 83 Windows \n",
    "{\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\",\n",
    "\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "\"Sec-Fetch-Site\": \"same-origin\",\n",
    "\"Sec-Fetch-Mode\": \"navigate\",\n",
    "\"Sec-Fetch-User\": \"?1\",\n",
    "\"Sec-Fetch-Dest\": \"document\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "]\n",
    "ordered_headers_list = []\n",
    "for headers in headers_list:\n",
    "    h = OrderedDict()\n",
    "for header,value in headers.items():\n",
    "    h[header]=value\n",
    "    ordered_headers_list.append(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff17dfd",
   "metadata": {},
   "source": [
    "# Pulls in an input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputname = input('URL Input Filename without extension (no more than 50 per run is recommended): ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulls in URL file:\n",
    "URLs = open(inputname + '.txt').readlines()\n",
    "#Check that they pulled in properly\n",
    "print(URLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3b93e",
   "metadata": {},
   "source": [
    "# Runs through the input file, scraping data from each one and putting it into a Python dictionary (set up above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to run the URLs through Soup and put their info in the Dictionary\n",
    "for i, url in enumerate(URLs, 0):\n",
    "    sleep(randint(5,100))    \n",
    "\n",
    "    url = URLs[i]        \n",
    "    #Pick a random browser headers\n",
    "    headers = random.choice(headers_list)\n",
    "    #Create a request session\n",
    "    r = requests.Session()\n",
    "    r.headers = headers\n",
    "    webpage = r.get(url)\n",
    "    \n",
    "    # Creating the Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")\n",
    "    # retrieving title\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"id\": 'productTitle'})\n",
    "        # Inner NavigableString Object\n",
    "        title_value = title.string\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip().replace(',', '')\n",
    "    except AttributeError:\n",
    "        title_string = \"NA\"\n",
    "    \n",
    "    #removes extra parenteses from title\n",
    "    titlesub1 = re.sub(r'\\(manga\\)|\\(Light Novel\\)|\\(novel\\)', '', title_string)\n",
    "    titlefix = re.sub(r'\\((.*?)\\)', '', titlesub1)\n",
    "    print(\"Title = \", titlefix)\n",
    "    \n",
    "    # retrieving author\n",
    "    try:\n",
    "        author = soup.find(\"a\", attrs={'class': 'contributorNameID'}).contents\n",
    "        authorString = author[0].getText()            \n",
    "    except AttributeError:\n",
    "        author2 = soup.find(\"span\", attrs={'class': 'author'})\n",
    "        name2 = author2.findAll(\"a\")\n",
    "        authorString = name2[0].getText()\n",
    "    print(\"Author = \", authorString)\n",
    "\n",
    "    # retrieving price\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'class': 'a-size-base a-color-price a-color-price'}).string.strip().replace(',', '')\n",
    "    # we are omitting unnecessary spaces and commas form our string\n",
    "    except AttributeError:\n",
    "        price = \"NA\"\n",
    "    print(\"Price = \", price)\n",
    "\n",
    "    # finding all li tags in ul and printing the text within it\n",
    "    data1 = soup.find(\"div\", attrs={'id': 'detailBullets_feature_div'})\n",
    "    info = data1.findAll(\"span\")\n",
    "    pub = info[2].getText()\n",
    "    isbn= info[14].getText()\n",
    "    print(\"Publication = \", pub)\n",
    "    print(\"ISBN = \", isbn)\n",
    "\n",
    "    # Append these to dictionary\n",
    "    dict['title'].append(titlefix) \n",
    "    dict['author'].append(authorString)\n",
    "    dict['price'].append(price)\n",
    "    dict['publication'].append(pub)\n",
    "    dict['isbn'].append(isbn)\n",
    "    \n",
    "    #Grab just the publisher's name for a separate column\n",
    "    pubsearch = re.compile(r'[^\\(]*')\n",
    "    pubtemp = pubsearch.search(pub)\n",
    "    pubname = pubtemp.group()\n",
    "    pubclean = re.sub(r';[^.]+', '', pubname)\n",
    "    print(\"Publisher = \", pubclean)\n",
    "    dict['pubname'].append(pubclean)\n",
    "    \n",
    "    #Grab just the year part for a separate column\n",
    "    yearsearch = re.compile(r'\\d\\d\\d\\d')\n",
    "    yeartemp = yearsearch.search(pub)\n",
    "    year= yeartemp.group()\n",
    "    print(\"Year = \", year)\n",
    "    dict['year'].append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350a9d3",
   "metadata": {},
   "source": [
    "# Optional: Prints the Dictionary so you can see the data retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486fc67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the Dictionary\n",
    "print (dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41615de",
   "metadata": {},
   "source": [
    "# Takes Dictionary and makes it into a Dataframe and then cleans it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80650b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Makes Dataframe\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "#Removes dash from ISBN\n",
    "df['isbn'] = df['isbn'].str.replace(\"-\",\"\")\n",
    "\n",
    "df.drop(columns= ['publication'], inplace=True)\n",
    "df = df[['title', 'author', 'year', 'pubname', 'isbn', 'price']]\n",
    "df.columns = df.columns.str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555673e",
   "metadata": {},
   "source": [
    "# Saves Dataframe to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newFile = input('Save new data as: ')\n",
    "df.to_excel(newFile + '.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
